# -*- coding: utf-8 -*-
"""ë¹…ì½˜í…ŒìŠ¤íŠ¸.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1La9-tWVJmWhlW1McTMQ3PqJS_fNH6h58
"""

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ê²°
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

# 1. ë³¸ì¸ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê²½ë¡œ
base_path = '/content/drive/MyDrive/bigcontest/'

# 2. íŒŒì¼ ê²½ë¡œ ì„¤ì •

file_info = base_path + 'big_data_set1_f.csv'
file_monthly = base_path + 'big_data_set2_f.csv'
file_customer = base_path + 'big_data_set3_f.csv'
file_map = base_path + 'map.csv'
df_map = pd.read_csv(file_map)

# 3. ë°ì´í„° ë¡œë“œ (encoding='cp949' ì¶”ê°€)
try:
    df_info = pd.read_csv(file_info, encoding='cp949')
    df_monthly = pd.read_csv(file_monthly, encoding='cp949')
    df_customer = pd.read_csv(file_customer, encoding='cp949')

    print("--- ğŸš€ ë°ì´í„° ë¡œë“œ ì„±ê³µ! (cp949 ì¸ì½”ë”©) ---")
    print("\n[ë°ì´í„°ì…‹ 1: ê°€ë§¹ì  ì •ë³´ (df_info)]")
    print(df_info.head())

    print("\n[ë°ì´í„°ì…‹ 2: ì›”ë³„ ì´ìš© ì •ë³´ (df_monthly)]")
    print(df_monthly.head())

    print("\n[ë°ì´í„°ì…‹ 3: ì›”ë³„ ê³ ê° ì •ë³´ (df_customer)]")
    print(df_customer.head())

except FileNotFoundError:
    print(f"!!! âŒ ì—ëŸ¬: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. í˜¹ì‹œ 'base_path'ê°€ ì •í™•í•œê°€ìš”?")
    print(f"ì…ë ¥ëœ ê²½ë¡œ: {base_path}")
except UnicodeDecodeError:
    print(f"!!! âŒ ì—ëŸ¬: 'cp949'ë¡œë„ í•´ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print(f"ë‹¤ë¥¸ ì¸ì½”ë”©('euc-kr')ì„ ì‹œë„í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"!!! âŒ ì—ëŸ¬ ë°œìƒ: {e}")

# í•œê¸€í°íŠ¸ ì„¤ì¹˜
!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

print("--- í°íŠ¸ ì„¤ì¹˜ ì™„ë£Œ ---")

# ë°ì´í„° ì „ì²˜ë¦¬
import matplotlib.pyplot as plt
import seaborn as sns

# íŠ¹ìˆ˜ê°’(SV)ì„ NaNìœ¼ë¡œ ë³€í™˜
df_monthly.replace(-999999.9, np.nan, inplace=True)
df_customer.replace(-999999.9, np.nan, inplace=True)

print("--- [df_customer] íŠ¹ìˆ˜ê°’ ì²˜ë¦¬ í›„ head() ---")
print(df_customer.head())
print("\nì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. df_customerì˜ -999999.9 ê°’ì´ NaNìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")

"""## 1ë²ˆ ì§ˆë¬¸
{ì¹´í˜ì—…ì¢… ê°€ë§¹ì } ì¹´í˜ì˜ ì£¼ìš” ë°©ë¬¸ ê³ ê° íŠ¹ì„±ì— ë”°ë¥¸ ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ ë° í™ë³´ì•ˆì„ ì‘ì„±
"""

# ì¹´í˜ ì—…ì¢… ì°¾ê¸°
# 1. df_info (ê°€ë§¹ì  ê°œìš”)ì—ì„œ ì—…ì¢… ì»¬ëŸ¼('HPSN_MCT_ZCD_NM')ì˜ ê³ ìœ ê°’ í™•ì¸
industry_names = df_info['HPSN_MCT_ZCD_NM'].unique()

print(f"--- [ì´ {len(industry_names)}ê°œì˜ ê³ ìœ  ì—…ì¢…ëª… ë°œê²¬] ---")
# ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ìƒìœ„ 50ê°œë§Œ ì¶œë ¥
print(industry_names[:50])

# 2. 'ì¹´í˜' ë˜ëŠ” 'ì»¤í”¼'ê°€ í¬í•¨ëœ ì—…ì¢…ëª… ì°¾ê¸°
cafe_related_names = [name for name in industry_names if 'ì¹´í˜' in name or 'ì»¤í”¼' in name]
print(f"\n--- [ì¹´í˜/ì»¤í”¼ ê´€ë ¨ ì—…ì¢…ëª…] ---")
print(cafe_related_names)

# 1. 'HPSN_MCT_ZCD_NM'(ì—…ì¢…ëª…) ì»¬ëŸ¼ì—ì„œ 'ì¹´í˜' ë˜ëŠ” 'ì»¤í”¼'ê°€ í¬í•¨ëœ ì—…ì¢… ì°¾ê¸°
cafe_industry_names = df_info[
    df_info['HPSN_MCT_ZCD_NM'].str.contains('ì¹´í˜|ì»¤í”¼', na=False)
]['HPSN_MCT_ZCD_NM'].unique()

print(f"--- [ì¹´í˜/ì»¤í”¼ ê´€ë ¨ ì—…ì¢…ëª…] ---")
print(cafe_industry_names)

# 2. í•´ë‹¹ ì—…ì¢…ì˜ ê°€ë§¹ì  ì •ë³´ë§Œ í•„í„°ë§
cafe_info_df = df_info[
    df_info['HPSN_MCT_ZCD_NM'].isin(cafe_industry_names)
].copy()

# 3. ì±—ë´‡ì—ê²Œ í•„ìš”í•œ ìµœì†Œ ì •ë³´ë§Œ ì„ íƒ
# (MCT_NMì€ ê°€ë§¹ì ëª…, HPSN_MCT_ZCD_NMì€ ì—…ì¢…ëª…ì…ë‹ˆë‹¤)
cafe_info_df = cafe_info_df[['ENCODED_MCT', 'MCT_NM', 'HPSN_MCT_ZCD_NM']]
print(f"\nì´ {len(cafe_info_df)}ê°œì˜ ì¹´í˜ ê°€ë§¹ì  ì •ë³´ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
print(cafe_info_df.head())

# 1. ë¶„ì„í•  ê³ ê° íŠ¹ì„± ì»¬ëŸ¼ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜
age_gender_cols = [
    'M12_MAL_1020_RAT', 'M12_MAL_30_RAT', 'M12_MAL_40_RAT',
    'M12_MAL_50_RAT', 'M12_MAL_60_RAT', 'M12_FME_1020_RAT',
    'M12_FME_30_RAT', 'M12_FME_40_RAT', 'M12_FME_50_RAT', 'M12_FME_60_RAT'
]

visit_purpose_cols = [
    'RC_M1_SHC_RSD_UE_CLN_RAT', # ê±°ì£¼
    'RC_M1_SHC_WP_UE_CLN_RAT',  # ì§ì¥
    'RC_M1_SHC_FLP_UE_CLN_RAT'  # ìœ ë™
]

visit_type_cols = [
    'MCT_UE_CLN_REU_RAT', # ì¬ë°©ë¬¸
    'MCT_UE_CLN_NEW_RAT'  # ì‹ ê·œ
]

# 2. 'ì¹´í˜' ê°€ë§¹ì ì˜ ê³ ê° ë°ì´í„°ë§Œ í•„í„°ë§
cafe_mct_list = cafe_info_df['ENCODED_MCT'].unique()
cafe_customer_df = df_customer[
    df_customer['ENCODED_MCT'].isin(cafe_mct_list)
]

# 3. ê°€ë§¹ì  IDë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‰ê·  í”„ë¡œí•„ ê³„ì‚°
profile_cols = age_gender_cols + visit_purpose_cols + visit_type_cols
cafe_profile_df = cafe_customer_df.groupby('ENCODED_MCT')[profile_cols].mean()

# ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ì¬ì„¤ì •
cafe_profile_df = cafe_profile_df.reset_index()

print("\n--- [ê°€ë§¹ì ë³„ í‰ê·  ê³ ê° í”„ë¡œí•„ ìƒì„± ì™„ë£Œ] ---")
print(cafe_profile_df.head())

# 1. ê°€ë§¹ì  ì •ë³´(ì´ë¦„)ì™€ ê³ ê° í”„ë¡œí•„(í‰ê· ê°’)ì„ 'ENCODED_MCT' ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
final_cafe_profiles_df = pd.merge(
    cafe_info_df,
    cafe_profile_df,
    on='ENCODED_MCT'
)

# 2. ì—…ì¢… í†µí•©: final_cafe_profiles_dfì— df_mapì„ ë³‘í•©í•˜ì—¬ 'map' ì»¬ëŸ¼ ìƒì„±
final_cafe_profiles_df = pd.merge(
    final_cafe_profiles_df,
    df_map[['HPSN_MCT_ZCD_NM', 'map']], # df_mapì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    on='HPSN_MCT_ZCD_NM',
    how='left'
)

print("\n--- [ìµœì¢… 'ì¹´í˜ í”„ë¡œí•„' ë°ì´í„°ì…‹ ì™„ì„±] ---")
print(final_cafe_profiles_df.head())

# 2. ì±—ë´‡ì´ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ì´ íŒŒì¼ì„ CSVë¡œ ì €ì¥
output_path = base_path + 'analysis_cafe_profiles.csv'
final_cafe_profiles_df.to_csv(output_path, index=False, encoding='utf-8-sig')

print(f"\níŒŒì¼ì´ '{output_path}' ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


# 3. ê²°ê³¼ í™•ì¸ (ì„ íƒ ì‚¬í•­)
print("\n--- [ì—…ì¢… 'map' ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ] ---")
print(final_cafe_profiles_df.head())

# 4. ì±—ë´‡ì´ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ì´ íŒŒì¼ì„ CSVë¡œ ì €ì¥
# (ê°€ì •: base_pathì™€ ìµœì¢… dfê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
output_path = base_path + 'analysis_cafe_profiles.csv'
final_cafe_profiles_df.to_csv(output_path, index=False, encoding='utf-8-sig')

print(f"\níŒŒì¼ì´ '{output_path}' ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

"""##2ë²ˆ ì§ˆë¬¸
{ì¬ë°©ë¬¸ë¥  30% ë¯¸ë§Œ ê°€ë§¹ì }ì˜ íƒ€ê²Ÿ ê³ ê°ê³¼ ë§ˆì¼€íŒ… ì£¼ë ¥ ì‹œê¸°ë¥¼ ì„ ì •í•˜ì—¬ ê°œì„  ë°©ì•ˆ ì œì‹œ
"""

# ì—…ì¢… ë¶„ë¥˜ (ì¤‘ë³µì—…ì¢… í†µí•©)
file_map = base_path + 'map.csv'
df_map = pd.read_csv(file_map)

# ê³ ê°íŠ¹ì„± ë³„ ì»¬ëŸ¼ ìƒì„±
PER_COLS = ['M12_MAL_1020_RAT', 'M12_MAL_30_RAT', 'M12_MAL_40_RAT', 'M12_MAL_50_RAT', 'M12_MAL_60_RAT',
            'M12_FME_1020_RAT', 'M12_FME_30_RAT', 'M12_FME_40_RAT', 'M12_FME_50_RAT', 'M12_FME_60_RAT']
LABELS = ['1020ë‚¨', '30ë‚¨', '40ë‚¨', '50ë‚¨', '60ë‚¨', '1020ì—¬', '30ì—¬', '40ì—¬', '50ì—¬', '60ì—¬']
BIG_LABELS = dict(zip(PER_COLS, LABELS))

PER_COLS2 = ['MCT_UE_CLN_NEW_RAT', 'RC_M1_SHC_RSD_UE_CLN_RAT',
             'RC_M1_SHC_WP_UE_CLN_RAT', 'RC_M1_SHC_FLP_UE_CLN_RAT']
LABELS2 = ['ì‹ ê·œê³ ê°','ê±°ì£¼ê³ ê°', 'ì§ì¥ê³ ê°', 'ìœ ë™ê³ ê°']
BIG_LABELS2 = dict(zip(PER_COLS2, LABELS2))

# ì—…ì¢… í†µí•©: df_infoì— df_mapì„ ë³‘í•©í•˜ì—¬ 'map' ì»¬ëŸ¼ ìƒì„±
df_info_merged = pd.merge(df_info, df_map, on='HPSN_MCT_ZCD_NM', how='left')

# ì›”ë³„ ë°ì´í„° ë³‘í•©
df_data_monthly = pd.merge(df_monthly, df_customer, on=['ENCODED_MCT','TA_YM'], how='outer')

# ìµœì¢… ë³‘í•©
big_df = pd.merge(df_info_merged, df_data_monthly, on='ENCODED_MCT', how='left')

# TA_YM ë‚ ì§œ í¬ë§·ìœ¼ë¡œ ë³€ê²½ ë° month ì»¬ëŸ¼ ìƒì„±
big_df['TA_YM'] = big_df['TA_YM'].astype(str).str[:4] + '-' + big_df['TA_YM'].astype(str).str[4:]
big_df['month'] = big_df['TA_YM'].str[-2:].astype(int)

# ì—…ì¢… í†µí•©
industry_re_rate_avg = big_df.groupby('map')['MCT_UE_CLN_REU_RAT'].mean().to_dict()

print("--- ì¬ë°©ë¬¸ë¥  ë°ì´í„° ë³‘í•© ì™„ë£Œ ---")
print(big_df[['MCT_NM', 'map', 'TA_YM', 'MCT_UE_CLN_REU_RAT'] + PER_COLS[:3]].head())

# ê°€ë§¹ì  í”„ë¡œí•„ ë°ì´í„° ì¶”ì¶œ

unique_mct_ids = big_df['ENCODED_MCT'].dropna().unique()
all_profiles = []

# ê° ENCODED_MCT ë³„ë¡œ í”„ë¡œí•„ ì·¨í•©
for mct_id in unique_mct_ids:
    mct_df = big_df[big_df['ENCODED_MCT'] == mct_id].copy()

    try:
        # ê°€ë§¹ì ëª… ë° ì—…ì¢… ì¶”ì¶œ
        mct_map = mct_df['map'].iloc[0]
        mct_name = mct_df['MCT_NM'].iloc[0]

        # ì¬ë°©ë¬¸ë¥  ë¶„ì„
        avg_re_rate = mct_df['MCT_UE_CLN_REU_RAT'].mean()

        # ì›”ë³„ ìµœê³ /ìµœì € ë¶„ì„
        monthly_avg = mct_df.groupby('month')['MCT_UE_CLN_REU_RAT'].mean()
        worst_month = int(monthly_avg.idxmin())
        best_month = int(monthly_avg.idxmax())
        worst_rate = monthly_avg.min()
        best_rate = monthly_avg.max()

        # ê³ ê° íŠ¹ì„± ë¶„ì„
        # ê°€ë§¹ì  ì¬ë°©ë¬¸ìœ¨ì´ 30% ë¯¸ë§Œì¸ ë ˆì½”ë“œë§Œ í•„í„°ë§
        low_re_rate_df = mct_df[mct_df['MCT_UE_CLN_REU_RAT'] < 30.0].copy()

        # í•„í„°ë§ëœ ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©
        target_df = low_re_rate_df if not low_re_rate_df.empty else mct_df

        # ë¶„ì„ ëŒ€ìƒ ë°ì´í„°ì˜ ê³ ê° ë¹„ìœ¨ í‰ê·  ê³„ì‚°
        per_mean = target_df[PER_COLS + PER_COLS2].mean(numeric_only=True).dropna()

        # PER_COLS (ì„±ë³„/ì—°ë ¹ëŒ€) - ê°€ì¥ ì ì€ ë¹„ìœ¨(worst)ì„ íƒ€ê²Ÿìœ¼ë¡œ ì¶”ì¶œ
        valid_per = per_mean.filter(PER_COLS)
        # 30% ë¯¸ë§Œì¸ ë ˆì½”ë“œì—ì„œ ê°€ì¥ ì ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ê°€ 'ê³µëµ ëŒ€ìƒ'
        worst_per_label = BIG_LABELS.get(valid_per.idxmin(), 'ì •ë³´ ì—†ìŒ') if not valid_per.empty else 'ì •ë³´ ì—†ìŒ'

        # PER_COLS2 (ê³ ê° ìœ í˜•) - ìµœê³ /ìµœì € ì¶”ì¶œ
        valid_per2 = per_mean.filter(PER_COLS2)
        best_per2_label = BIG_LABELS2.get(valid_per2.idxmax(), 'ì •ë³´ ì—†ìŒ') if not valid_per2.empty else 'ì •ë³´ ì—†ìŒ'
        worst_per2_label = BIG_LABELS2.get(valid_per2.idxmin(), 'ì •ë³´ ì—†ìŒ') if not valid_per2.empty else 'ì •ë³´ ì—†ìŒ'

        # ì¬ë°©ë¬¸ë¥  30% ë¯¸ë§Œ ì—¬ë¶€ ì§„ë‹¨
        # ì—…ì¢… í‰ê·  ì¬ë°©ë¬¸ë¥  ì¡°íšŒ
        industry_avg = industry_re_rate_avg.get(mct_map, np.nan)

        # ê°€ë§¹ì /ì—…ì¢… ì¬ë°©ë¬¸ë¥  30% ë¯¸ë§Œ ì—¬ë¶€
        is_low_mct_re_rate = avg_re_rate < 30.0
        is_low_industry_re_rate = industry_avg < 30.0 if not np.isnan(industry_avg) else False

        # 4. ìµœì¢… í”„ë¡œí•„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
        profile_data = {
            "mct_id": mct_id,
            "mct_name": mct_name,
            "map": mct_map,
            "avg_re_rate": avg_re_rate,
            "is_low_mct_re_rate": is_low_mct_re_rate,
            "industry_avg_re_rate": industry_avg,
            "is_low_industry_re_rate": is_low_industry_re_rate,
            "worst_month": worst_month,
            "worst_rate": worst_rate,
            "best_month": best_month,
            "target_per_segment": worst_per_label,
            "best_per_type": best_per2_label,
            "worst_per_type": worst_per2_label,
        }
        all_profiles.append(profile_data)

    except Exception as e:
        continue

print(f"ë¶„ì„ ì™„ë£Œ. ì´ {len(all_profiles)}ê°œì˜ ê°€ë§¹ì  í”„ë¡œí•„ ë°ì´í„° ì·¨í•©.")

# ì·¨í•©ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
under_30per_re_rate = pd.DataFrame(all_profiles)

print(under_30per_re_rate[['mct_id', 'mct_name', 'map', 'avg_re_rate', 'is_low_mct_re_rate', 'is_low_industry_re_rate', 'target_per_segment']].head())

# ì±—ë´‡ì´ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ CSVë¡œ ì €ì¥
output_path = base_path + 'under_30per_re_rate.csv'
under_30per_re_rate.to_csv(output_path, index=False, encoding='utf-8-sig')

print(f"\níŒŒì¼ì´ '{output_path}' ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

"""## 3ë²ˆ ì§ˆë¬¸
{ìš”ì‹ì—…ì¢… ê°€ë§¹ì } ë§¤ì¥ì˜ í˜„ì¬ ê°€ì¥ í° ë¬¸ì œì  ë° ì´ë¥¼ ë³´ì™„í•  ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ì™€ ê·¼ê±°ë¥¼ ì œì‹œ
"""

# êµ¬ê°„ ë°ì´í„°ë¥¼ ìˆ«ì ì ìˆ˜ë¡œ ë³€í™˜
# (ì˜ˆ: "1_10%ì´í•˜" -> 1.0, "6_90%ì´ˆê³¼(í•˜ìœ„ 10% ì´í•˜)" -> 6.0)
rank_cols = ['MCT_OPE_MS_CN', 'RC_M1_SAA', 'RC_M1_TO_UE_CT', 'RC_M1_UE_CUS_CN', 'RC_M1_AV_NP_AT', 'APV_CE_RAT']

for col in rank_cols:
    df_monthly[f'{col}_score'] = df_monthly[col].str[0].astype(float)

print("\n--- 'df_monthly'ì— ìˆ«ì ìŠ¤ì½”ì–´ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ ---")
print(df_monthly[['RC_M1_SAA', 'RC_M1_SAA_score']].head())

# --- 1. â‘  ìµœì‹  ì›” ì •ë³´ (P2, P3 ì§„ë‹¨ìš©) ---
# TA_YM(ê¸°ì¤€ë…„ì›”)ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„, ê°€ë§¹ì ë³„ ì²« ë²ˆì§¸(ê°€ì¥ ìµœì‹ ) ë°ì´í„°ë§Œ ë‚¨ê¹€
df_recent = df_monthly.sort_values('TA_YM', ascending=False).drop_duplicates('ENCODED_MCT')
print(f"ê°€ë§¹ì ë³„ 'ìµœì‹  ì›”' ì •ë³´ ìƒì„± ì™„ë£Œ (ì´ {len(df_recent)}ê±´)")

# --- 2. â‘¡ ê³¼ê±° í†µê³„ (P1 ì§„ë‹¨ìš©) ---
# ê°€ë§¹ì ë³„ë¡œ P1 ì§„ë‹¨ì— í•„ìš”í•œ 'ë§¤ì¶œ'ê³¼ 'ê³ ê° ìˆ˜' ìŠ¤ì½”ì–´ì˜ í‰ê· (mean)ê³¼ í‘œì¤€í¸ì°¨(std) ê³„ì‚°
score_cols = ['RC_M1_SAA_score', 'RC_M1_UE_CUS_CN_score']
df_stats = df_monthly.groupby('ENCODED_MCT')[score_cols].agg(['mean', 'std'])
df_stats.columns = ['_'.join(col) for col in df_stats.columns.values] # ì»¬ëŸ¼ëª… ë³‘í•©
print("ê°€ë§¹ì ë³„ 'ê³¼ê±° í†µê³„' (í‰ê· , í‘œì¤€í¸ì°¨) ìƒì„± ì™„ë£Œ")

# --- 3. â‘¢ ê³ ê° í”„ë¡œí•„ (P4 ì§„ë‹¨ìš©) ---
# (1ë²ˆ ì§ˆë¬¸ì—ì„œ 'ì¹´í˜'ë§Œ ëŒ€ìƒìœ¼ë¡œ í–ˆë˜ ê²ƒì„ 'ì „ì²´' ê°€ë§¹ì ìœ¼ë¡œ í™•ëŒ€)
customer_cols = [col for col in df_customer.columns if 'RAT' in col]
df_customer_profile = df_customer.groupby('ENCODED_MCT')[customer_cols].mean()
print("ê°€ë§¹ì ë³„ 'í‰ê·  ê³ ê° í”„ë¡œí•„' ìƒì„± ì™„ë£Œ")

# 1. df_infoì™€ df_recent ë³‘í•©
df_analysis = pd.merge(df_info[['ENCODED_MCT', 'MCT_NM', 'HPSN_MCT_ZCD_NM']],
                       df_recent,
                       on='ENCODED_MCT',
                       how='left') # ëª¨ë“  ê°€ë§¹ì  ì •ë³´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ

# 2. df_stats ë³‘í•©
df_analysis = pd.merge(df_analysis, df_stats, on='ENCODED_MCT', how='left')

# 3. df_customer_profile ë³‘í•©
df_analysis = pd.merge(df_analysis, df_customer_profile, on='ENCODED_MCT', how='left')

print("\n--- 'ë§ˆìŠ¤í„° ì§„ë‹¨ íŒŒì¼' ë³‘í•© ì™„ë£Œ ---")
print(f"ìµœì¢… ì§„ë‹¨ ëŒ€ìƒ ê°€ë§¹ì  ìˆ˜: {len(df_analysis)}")
print(df_analysis.head())

# --- [P1] 1ìˆœìœ„: ì‹œê³„ì—´ ê¸‰ë½ (Z-score) ì§„ë‹¨ ---
# (ìµœì‹  ìŠ¤ì½”ì–´ - í‰ê· ) / í‘œì¤€í¸ì°¨. (ìŠ¤ì½”ì–´ëŠ” ë†’ì„ìˆ˜ë¡ ë‚˜ì¨)
z_sales = (df_analysis['RC_M1_SAA_score'] - df_analysis['RC_M1_SAA_score_mean']) / df_analysis['RC_M1_SAA_score_std']
z_customer = (df_analysis['RC_M1_UE_CUS_CN_score'] - df_analysis['RC_M1_UE_CUS_CN_score_mean']) / df_analysis['RC_M1_UE_CUS_CN_score_std']

# Z-scoreê°€ 1.5 (í‰ì†Œë³´ë‹¤ 1.5 í‘œì¤€í¸ì°¨ ì´ìƒ ë‚˜ë¹ ì§) ì´ìƒì¸ ê²½ìš°
df_analysis['P1_Problem'] = (z_sales > 1.5) | (z_customer > 1.5)
df_analysis['P1_Details'] = np.where(z_sales > 1.5, f"ë§¤ì¶œ ê¸‰ë½(Z-score:{z_sales.round(2)})", "") + \
                          np.where(z_customer > 1.5, f"ê³ ê° ê¸‰ê°(Z-score:{z_customer.round(2)})", "")

# --- [P2] 2ìˆœìœ„: 4ë¶„ë©´ ë§¤íŠ¸ë¦­ìŠ¤ ì§„ë‹¨ ---
# (ìŠ¤ì½”ì–´ëŠ” 1~6ì , 3.5ê°€ ì¤‘ì•™ê°’)
acq_score = (df_analysis['RC_M1_TO_UE_CT_score'] + df_analysis['RC_M1_UE_CUS_CN_score']) / 2
profit_score = (df_analysis['RC_M1_SAA_score'] + df_analysis['RC_M1_AV_NP_AT_score']) / 2

# ê¸°ì¤€ ì„¤ì • (High=ì¢‹ìŒ(<=3.0), Low=ë‚˜ì¨(>=4.0), Avg=ì• ë§¤(3.0~4.0))
cond_acq_high = (acq_score <= 3.0)
cond_acq_low = (acq_score >= 4.0)
cond_profit_high = (profit_score <= 3.0)
cond_profit_low = (profit_score >= 4.0)

# ìœ í˜• ë¶„ë¥˜
cond_list = [
    (cond_acq_high & cond_profit_high), # P2_ìŠ¤íƒ€ë§¤ì¥
    (cond_acq_low & cond_profit_high),  # P2_ìˆ¨ì€ë§›ì§‘ (ë¬¸ì œ)
    (cond_acq_high & cond_profit_low),  # P2_ë°•ë¦¬ë‹¤ë§¤ (ë¬¸ì œ)
    (cond_acq_low & cond_profit_low)    # P2_ìœ„ê¸°ë§¤ì¥ (ë¬¸ì œ)
]
choice_list = ['P2_ìŠ¤íƒ€ë§¤ì¥', 'P2_ìˆ¨ì€ë§›ì§‘', 'P2_ë°•ë¦¬ë‹¤ë§¤', 'P2_ìœ„ê¸°ë§¤ì¥']
df_analysis['P2_Quadrant'] = np.select(cond_list, choice_list, default='P2_ì• ë§¤í•¨')

# --- [P3] 3ìˆœìœ„: ì·¨ì†Œìœ¨ ì§„ë‹¨ ---
# ë°°ë‹¬ ìœ ë¬´ í™•ì¸ (DLV_SAA_RATì´ NaNì´ ì•„ë‹ˆë©´ ë°°ë‹¬ ë§¤ì¥)
cond_delivery = df_analysis['DLV_SAA_RAT'].notna()
cond_no_delivery = df_analysis['DLV_SAA_RAT'].isna()

# ê¸°ì¤€ ì ìš© (ë°°ë‹¬: 5~6êµ¬ê°„, í™€: 3~6êµ¬ê°„ì¼ ë•Œ ë¬¸ì œ)
cond_delivery_high_cancel = (cond_delivery & (df_analysis['APV_CE_RAT_score'] >= 5.0))
cond_no_delivery_high_cancel = (cond_no_delivery & (df_analysis['APV_CE_RAT_score'] >= 3.0))

df_analysis['P3_Problem'] = cond_delivery_high_cancel | cond_no_delivery_high_cancel
df_analysis['P3_Details'] = np.where(df_analysis['P3_Problem'], f"ì·¨ì†Œìœ¨ ë†’ìŒ(êµ¬ê°„:{df_analysis['APV_CE_RAT_score']})", "")

# --- [P4] 4ìˆœìœ„: ê³ ê° ë¶ˆê· í˜• ì§„ë‹¨ ---
# (ë¶„ì„í•  ê³ ê°ì¸µ ì»¬ëŸ¼ë§Œ ì‚¬ìš©)
age_gender_cols = [col for col in df_customer_profile.columns if 'MAL' in col or 'FME' in col]

# í‰ê·  ë¹„ì¤‘ì´ 5% ë¯¸ë§Œì¸ ì„¸ê·¸ë¨¼íŠ¸ê°€ 3ê°œ ì´ìƒì¸ ê²½ìš° (ë„ˆë¬´ í¸ì¤‘ë¨)
missing_segments_count = (df_analysis[age_gender_cols] < 5.0).sum(axis=1)
df_analysis['P4_Problem'] = (missing_segments_count >= 3)
df_analysis['P4_Details'] = np.where(df_analysis['P4_Problem'], f"ê³ ê°ì¸µ í¸ì¤‘(5%ë¯¸ë§Œ {missing_segments_count}ê°œ)", "")

print("P1, P2, P3, P4 ì§„ë‹¨ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ.")

# --- ìµœì¢… ì§„ë‹¨ (ìš°ì„ ìˆœìœ„ ì ìš©) ---
final_cond_list = [
    df_analysis['P1_Problem'] == True,
    df_analysis['P2_Quadrant'].isin(['P2_ìœ„ê¸°ë§¤ì¥', 'P2_ìˆ¨ì€ë§›ì§‘', 'P2_ë°•ë¦¬ë‹¤ë§¤']),
    df_analysis['P3_Problem'] == True,
    df_analysis['P4_Problem'] == True
]

final_choice_list = [
    'P1_ë§¤ì¶œ/ê³ ê° ê¸‰ë½', # 1ìˆœìœ„
    df_analysis['P2_Quadrant'], # 2ìˆœìœ„
    'P3_ë†’ì€ ì·¨ì†Œìœ¨',    # 3ìˆœìœ„
    'P4_ê³ ê°ì¸µ ë¶ˆê· í˜•'   # 4ìˆœìœ„
]

df_analysis['FINAL_DIAGNOSIS'] = np.select(final_cond_list, final_choice_list, default='P0_ê±´ê°•í•¨')

# ì§„ë‹¨ ì„¸ë¶€ë‚´ìš© ì»¬ëŸ¼
details_cond_list = [
    df_analysis['FINAL_DIAGNOSIS'] == 'P1_ë§¤ì¶œ/ê³ ê° ê¸‰ë½',
    df_analysis['FINAL_DIAGNOSIS'].isin(['P2_ìœ„ê¸°ë§¤ì¥', 'P2_ìˆ¨ì€ë§›ì§‘', 'P2_ë°•ë¦¬ë‹¤ë§¤']),
    df_analysis['FINAL_DIAGNOSIS'] == 'P3_ë†’ì€ ì·¨ì†Œìœ¨',
    df_analysis['FINAL_DIAGNOSIS'] == 'P4_ê³ ê°ì¸µ ë¶ˆê· í˜•'
]
details_choice_list = [
    df_analysis['P1_Details'],
    df_analysis['P2_Quadrant'] + f"(ìœ ì¹˜:{acq_score.round(2)}, ìˆ˜ìµ:{profit_score.round(2)})",
    df_analysis['P3_Details'],
    df_analysis['P4_Details']
]
df_analysis['DIAGNOSIS_DETAILS'] = np.select(details_cond_list, details_choice_list, default='íŠ¹ì´ ë¬¸ì œ ì—†ìŒ')


df_analysis = pd.merge(
    df_analysis,
    df_map[['HPSN_MCT_ZCD_NM', 'map']],
    on='HPSN_MCT_ZCD_NM',
    how='left'
)

# 2. ì±—ë´‡ìš© 'ì§„ë‹¨ ì°¨íŠ¸' íŒŒì¼ ì €ì¥ (ì—…ë°ì´íŠ¸ëœ df_analysis ì‚¬ìš©)
output_path_q3 = base_path + 'analysis_problem_diagnosis.csv'
df_analysis.to_csv(output_path_q3, index=False, encoding='utf-8-sig')

print(f"\n--- 3ë²ˆ ì§ˆë¬¸ìš© 'ì§„ë‹¨ ì°¨íŠ¸' íŒŒì¼ ì €ì¥ ì™„ë£Œ! (map ì»¬ëŸ¼ ì¶”ê°€) ---")
print(f"ê²½ë¡œ: {output_path_q3}") # ì´ ì¶œë ¥ë¬¸ë„ ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.
print("\n[ìµœì¢… ì§„ë‹¨ ê²°ê³¼ ìƒ˜í”Œ (map ì»¬ëŸ¼ í¬í•¨)]")
print(df_analysis[['MCT_NM', 'FINAL_DIAGNOSIS', 'DIAGNOSIS_DETAILS', 'map']].sample(10))



# --- ì±—ë´‡ìš© 'ì§„ë‹¨ ì°¨íŠ¸' íŒŒì¼ ì €ì¥ ---
#output_path_q3 = base_path + 'analysis_problem_diagnosis.csv'
#df_analysis.to_csv(output_path_q3, index=False, encoding='utf-8-sig')

#print(f"\n--- 3ë²ˆ ì§ˆë¬¸ìš© 'ì§„ë‹¨ ì°¨íŠ¸' íŒŒì¼ ì €ì¥ ì™„ë£Œ! ---")
#print(f"ê²½ë¡œ: {output_path_q3}")
#print("\n[ìµœì¢… ì§„ë‹¨ ê²°ê³¼ ìƒ˜í”Œ]")
#print(df_analysis[['MCT_NM', 'FINAL_DIAGNOSIS', 'DIAGNOSIS_DETAILS']].sample(10))

"""## 4ë²ˆ ì§ˆë¬¸
íƒë¼ **ì˜ ì›”ë³„ ë§¤ì¶œì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ë§ˆì¼€íŒ… ì „ëµì„ ì œì‹œí•´ì¤˜
"""

try:

    # 'ENCODED_MCT' (ê°€ë§¹ì  ID) ë³„ë¡œ 'TA_YM' (ê¸°ì¤€ë…„ì›”)ì˜ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤.
    month_counts = df_monthly.groupby('ENCODED_MCT').size()

    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ê³  ì»¬ëŸ¼ëª…ì„ 'MonthCount'ë¡œ ì§€ì •
    month_counts_df = month_counts.reset_index(name='MonthCount')

    # 'MonthCount'ê°€ ë§ì€ ìˆœì„œ (ë‚´ë¦¼ì°¨ìˆœ)ë¡œ ì •ë ¬
    month_counts_df_sorted = month_counts_df.sort_values(by='MonthCount', ascending=False)

    # ê°€ë§¹ì  ì´ë¦„('MCT_NM')ê³¼ ì—…ì¢…('HPSN_MCT_ZCD_NM')ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    merged_counts_df = pd.merge(
        month_counts_df_sorted,
        df_info[['ENCODED_MCT', 'MCT_NM', 'HPSN_MCT_ZCD_NM']],
        on='ENCODED_MCT',
        how='left'
    )

    # ìƒìœ„ 20ê°œ ê°€ë§¹ì  ì¶œë ¥
    print("\n--- [ì›”ë³„ ë°ì´í„°(ê¸°ì¤€ë…„ì›”)ê°€ ê°€ì¥ ë§ì€ ê°€ë§¹ì  Top 20] ---")
    print(merged_counts_df.head(60))

    # ì „ì²´ì ì¸ ë¶„í¬ í™•ì¸ (ìµœëŒ€, ìµœì†Œ, í‰ê·  ê°œìˆ˜)
    print("\n\n--- [ì›”ë³„ ë°ì´í„° ë³´ìœ  ê°œìˆ˜ í†µê³„] ---")
    print(merged_counts_df['MonthCount'].describe())

except FileNotFoundError:
    print(f"!!! âŒ ì—ëŸ¬: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. í˜¹ì‹œ 'base_path'ê°€ '{base_path}'(ì´)ê°€ ë§ë‚˜ìš”?")
except Exception as e:
    print(f"!!! âŒ ì—ëŸ¬ ë°œìƒ: {e}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ë¶„ì„í•  ê°€ë§¹ì  ID
TARGET_MCT_ID = 'FEDAD7667E'

try:

    # ê°€ë§¹ì  ì´ë¦„ ì°¾ê¸°
    merchant_name_series = df_info[df_info['ENCODED_MCT'] == TARGET_MCT_ID]['MCT_NM']
    if not merchant_name_series.empty:
        merchant_name = merchant_name_series.values[0]
    else:
        merchant_name = TARGET_MCT_ID # ì´ë¦„ì„ ëª»ì°¾ìœ¼ë©´ ID ì‚¬ìš©

    print(f"ë¶„ì„ ëŒ€ìƒ: {merchant_name} (ID: {TARGET_MCT_ID})")

    # í•´ë‹¹ ê°€ë§¹ì ì˜ ì›”ë³„ ë°ì´í„° í•„í„°ë§
    df_target = df_monthly[df_monthly['ENCODED_MCT'] == TARGET_MCT_ID].copy()

    if df_target.empty:
        print(f"!!! âŒ ì—ëŸ¬: {TARGET_MCT_ID}ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # 'ë§¤ì¶œê¸ˆì•¡ êµ¬ê°„'ì„ ìˆ«ì ì ìˆ˜ë¡œ ë³€í™˜
        # "1_10%ì´í•˜" -> 1.0, "6_90%ì´ˆê³¼" -> 6.0
        # ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ë§¤ì¶œì´ 'ë†’ì€' êµ¬ê°„ (ìƒìœ„ê¶Œ)
        df_target['Sales_Score'] = df_target['RC_M1_SAA'].str[0].astype(float)

        # 'ê¸°ì¤€ë…„ì›”'ì„ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
        # 'TA_YM'ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ xì¶• ë ˆì´ë¸”ë¡œ ì‚¬ìš©
        df_target['TA_YM_str'] = df_target['TA_YM'].astype(str)
        df_target = df_target.sort_values(by='TA_YM')

        print("\n--- [ë§¤ì¶œê¸ˆì•¡ êµ¬ê°„ ì ìˆ˜ ë³€í™˜ ê²°ê³¼ (2023-2024)] ---")
        # í•´ë‹¹ ê°€ë§¹ì ì˜ 24ê°œì›”ì¹˜ ë°ì´í„°ë¥¼ ëª¨ë‘ ì¶œë ¥
        print(df_target[['TA_YM_str', 'RC_M1_SAA', 'Sales_Score']].to_string(index=False))

        # í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ë¥¼ ìœ„í•´)
        !sudo apt-get install -y fonts-nanum
        !sudo fc-cache -fv
        !rm ~/.cache/matplotlib -rf
        plt.rc('font', family='NanumBarunGothic')
        print("\n(ì½”ë©ì—ì„œ í•œê¸€ í°íŠ¸ ì„¤ì •ì„ ì‹¤í–‰í–ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤)")

        plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

        # ì‹œê°í™” (Line Plot)
        plt.figure(figsize=(15, 7))

        # lineplot ìƒì„±
        ax = sns.lineplot(
            data=df_target,
            x='TA_YM_str',
            y='Sales_Score',
            marker='o', # ê° ì›”ì— ì  í‘œì‹œ
            markersize=8
        )

        # ê·¸ë˜í”„ ì œëª© ë° ë ˆì´ë¸” ì„¤ì •
        plt.title(f"[{merchant_name}] 2ë…„ê°„ ë§¤ì¶œê¸ˆì•¡ êµ¬ê°„(Rank) ë³€í™” ì¶”ì´", fontsize=18, pad=20)
        plt.xlabel("ê¸°ì¤€ ë…„ì›” (TA_YM)", fontsize=12, labelpad=15)
        plt.ylabel("ë§¤ì¶œê¸ˆì•¡ êµ¬ê°„ ì ìˆ˜ (1ì  = ìƒìœ„ 10% ì´ë‚´)", fontsize=12, labelpad=15)

        # xì¶• ë ˆì´ë¸” 90ë„ íšŒì „ (24ê°œê°€ ê²¹ì¹˜ë¯€ë¡œ)
        plt.xticks(rotation=90)

        # Yì¶• ë°˜ì „: 1ì ì´ 'ìµœê³ 'ì´ë¯€ë¡œ ìœ„ë¡œ, 6ì ì´ 'ìµœí•˜'ì´ë¯€ë¡œ ì•„ë˜ë¡œ ê°€ê²Œ í•¨
        ax.invert_yaxis()

        # yì¶• ëˆˆê¸ˆì„ 1, 2, 3, 4, 5, 6 ì •ìˆ˜ë¡œ ì„¤ì •
        plt.yticks([1.0, 2.0, 3.0, 4.0, 5.0, 6.0])

        plt.grid(True, linestyle='--', alpha=0.6) # ê·¸ë¦¬ë“œ ì¶”ê°€
        plt.tight_layout() # ë ˆì´ì•„ì›ƒ ìµœì í™”

        # ê·¸ë˜í”„ íŒŒì¼ë¡œ ì €ì¥
        output_filename = 'sales_trend.png'
        plt.savefig(output_filename)


        print(f"\nê·¸ë˜í”„ê°€ '{output_filename}' ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # --- [ì±—ë´‡ í”„ë¡¬í”„íŠ¸ ìƒì„±ì„ ìœ„í•œ ë¶„ì„ íŒŒíŠ¸ ] ---

        # (ì ìˆ˜(Sales_Score)ê°€ ë‚®ì„ìˆ˜ë¡(ascending=True) ë§¤ì¶œì´ ë†’ì€ ê²ƒ)
        df_sorted_high = df_target.sort_values(by='Sales_Score', ascending=True)
        # .head(3)ëŠ” ìƒìœ„ 3ê°œë¥¼ ë½‘ì•„ëƒ„
        high_months = df_sorted_high['TA_YM_str'].head(3).tolist()

        # (ì ìˆ˜(Sales_Score)ê°€ ë†’ì„ìˆ˜ë¡(ascending=False) ë§¤ì¶œì´ ë‚®ì€ ê²ƒ)
        df_sorted_low = df_target.sort_values(by='Sales_Score', ascending=False)
        low_months = df_sorted_low['TA_YM_str'].head(3).tolist()

        print("\n\n--- [ì±—ë´‡ í”„ë¡¬í”„íŠ¸ìš© ë¶„ì„ ê²°ê³¼] ---")
        print(f"ë§¤ì¶œì´ ê°€ì¥ ë†’ì€ Top 3 ì›”: {high_months}")
        print(f"ë§¤ì¶œì´ ê°€ì¥ ë‚®ì€ Top 3 ì›”: {low_months}")
        print("--- [ë¶„ì„ ì™„ë£Œ] ---")

except FileNotFoundError:
    print(f"!!! âŒ ì—ëŸ¬: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. í˜¹ì‹œ 'base_path'ê°€ '{base_path}'(ì´)ê°€ ë§ë‚˜ìš”?")
except Exception as e:
    print(f"!!! âŒ ì—ëŸ¬ ë°œìƒ: {e}")

"""## 5ë²ˆ ì§ˆë¬¸
í‚´ìŠ¤**ì´ ì†í•œ ìƒê¶Œ ë‚´ì—ì„œ ê°™ì€ ì—…ì¢… ë§¤ì¥ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ í˜„ì¬ ìˆœìœ„ê°€ ì–´ë–»ê²Œ ë˜ê³ , 1ìœ„ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ê°œì„ í•˜ê±°ë‚˜ ì§‘ì¤‘í•´ì•¼ í•  ë§ˆì¼€íŒ… í¬ì¸íŠ¸ê°€ ë¬´ì—‡ì¸ì§€ ë¶„ì„í•´ì¤˜.
"""

try:
    # ë¶„ì„ì— í•„ìš”í•œ íŒŒì¼ 2ê°œ ë¡œë“œ (df_info, df_analysis_q3)
    df_info = pd.read_csv(base_path + 'big_data_set1_f.csv', encoding='cp949')
    df_analysis_q3 = pd.read_csv(base_path + 'analysis_problem_diagnosis.csv', encoding='utf-8-sig')
    print("ë°ì´í„° ë¡œë“œ ì™„ë£Œ (df_info, df_analysis_q3)")

    # 'ì„ì‹œ ë¶„ì„ìš©' DF ìƒì„± (Q3 ë§ˆìŠ¤í„° + ìƒê¶Œëª… ê²°í•©)
    df_temp_analysis = pd.merge(
        df_analysis_q3,
        df_info[['ENCODED_MCT', 'HPSN_MCT_BZN_CD_NM']], # 'ìƒê¶Œëª…' ì»¬ëŸ¼ë§Œ ê°€ì ¸ì˜´
        on='ENCODED_MCT',
        how='left'
    )

    # (Step 1) ìƒê¶Œì´ 'ëšì„¬'ì¸ ê°€ê²Œ ì¶”ì¶œ (ì •í™•íˆ ì¼ì¹˜)
    seongsu_stores = df_temp_analysis[
        df_temp_analysis['HPSN_MCT_BZN_CD_NM'] == 'ëšì„¬'
    ].copy()
    print(f"\n[Step 1] 'ëšì„¬' ìƒê¶Œ ë§¤ì¥ {len(seongsu_stores)}ê°œ ì¶”ì¶œ")

    # (Step 2) ê·¸ ì¤‘ ì—…ì¢…ì´ 'ì¹˜í‚¨'ì¸ ê°€ê²Œ ì¶”ì¶œ (ì •í™•íˆ ì¼ì¹˜)
    chicken_stores_in_seongsu = seongsu_stores[
        seongsu_stores['HPSN_MCT_ZCD_NM'] == 'ì¹˜í‚¨' # <-- ìˆ˜ì •ë¨
    ].copy()
    print(f"[Step 2] 'ì¹˜í‚¨' ì—…ì¢… ë§¤ì¥ {len(chicken_stores_in_seongsu)}ê°œ ì¶”ì¶œ")

    # (Step 3) ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ì—…

    # 'ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„'(M12_SME_RY_SAA_PCE_RT) ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚®ì„ìˆ˜ë¡ 1ë“±)
    df_final_list = chicken_stores_in_seongsu.sort_values(by='M12_SME_RY_SAA_PCE_RT', ascending=True)

    # ê²°ê³¼ ì¶œë ¥
    columns_to_show = [
        'MCT_NM',                # ë§¤ì¥ ì´ë¦„
        'HPSN_MCT_BZN_CD_NM',    # ìƒê¶Œëª…
        'HPSN_MCT_ZCD_NM',       # ì—…ì¢…ëª…
        'M12_SME_RY_SAA_PCE_RT'  # â˜…ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„(%)
    ]

    print("\n\n--- [Step 3: 'ëšì„¬' ìƒê¶Œ 'ì¹˜í‚¨' ë§¤ì¥ 'ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„' ë¦¬ìŠ¤íŠ¸] ---")
    if df_final_list.empty:
        print("!!! âŒ ì—ëŸ¬: í•´ë‹¹ ì¡°ê±´(ëšì„¬ + ì¹˜í‚¨)ì˜ ë§¤ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # .to_string()ìœ¼ë¡œ ëª¨ë“  ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶œë ¥
        print(df_final_list[columns_to_show].to_string())

        # (Bonus) 'í‚´ìŠ¤**'ì˜ ìˆœìœ„ì™€ 1ìœ„ ë§¤ì¥ ì°¾ê¸°
        kims_store = df_final_list[df_final_list['MCT_NM'] == 'í‚´ìŠ¤**']
        first_place_store = df_final_list.iloc[0]

        print("\n\n--- [1ìœ„ ë‹¬ì„± ì „ëµ ë¶„ì„ìš© ê·¼ê±°] ---")
        if not kims_store.empty:
            print(f"í‚´ìŠ¤**ì˜ í˜„ì¬ 'ì—…ì¢… ë‚´ ìˆœìœ„': {kims_store['M12_SME_RY_SAA_PCE_RT'].values[0]:.1f}%")
        else:
            print("!!! âŒ ê²½ê³ : 'í‚´ìŠ¤**' ìƒí˜¸ëª…ì„ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ìƒí˜¸ëª… í™•ì¸ í•„ìš”)")

        print(f"1ìœ„ ë§¤ì¥: {first_place_store['MCT_NM']} (ìˆœìœ„: {first_place_store['M12_SME_RY_SAA_PCE_RT']:.1f}%)")
        print(f"1ìœ„ ë§¤ì¥ ID (ë¶„ì„ìš©): {first_place_store['ENCODED_MCT']}")


except FileNotFoundError as e:
    print(f"!!! âŒ ì—ëŸ¬: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
except KeyError as e:
    print(f"!!! âŒ ì—ëŸ¬: ì»¬ëŸ¼ëª…ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì˜ˆ: {e})")
    print("Q3 ë§ˆìŠ¤í„° íŒŒì¼('analysis_problem_diagnosis.csv')ì´ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
except Exception as e:
    print(f"!!! âŒ ì—ëŸ¬ ë°œìƒ: {e}")

import streamlit as st
import pandas as pd
import numpy as np

# --- ë°ì´í„° ë¡œë”© (ì•± ì‹¤í–‰ ì‹œ 1ë²ˆë§Œ ì‹¤í–‰) ---
@st.cache_data
def load_data():
    """
    ë¶„ì„ì— í•„ìš”í•œ 2ê°œì˜ ë§ˆìŠ¤í„° íŒŒì¼ì„ ë¡œë“œí•˜ê³ , 'ìƒê¶Œëª…'ì„ ê²°í•©í•œ
    ìµœì¢… ë¶„ì„ìš© ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        df_info = pd.read_csv('big_data_set1_f.csv', encoding='cp949')
        df_analysis_q3 = pd.read_csv('analysis_problem_diagnosis.csv', encoding='utf-8-sig')

        # 'ì„ì‹œ ë¶„ì„ìš©' DF ìƒì„± (Q3 ë§ˆìŠ¤í„° + ìƒê¶Œëª… ê²°í•©)
        df_merged = pd.merge(
            df_analysis_q3,
            df_info[['ENCODED_MCT', 'HPSN_MCT_BZN_CD_NM']],
            on='ENCODED_MCT',
            how='left'
        )
        return df_merged
    except FileNotFoundError:
        st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'big_data_set1_f.csv'ì™€ 'analysis_problem_diagnosis.csv' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None

# --- í•µì‹¬ ë¶„ì„ í•¨ìˆ˜ ---
def analyze_competitors(df, store_name):
    """
    ì „ì²´ ë°ì´í„°í”„ë ˆì„ê³¼ íŠ¹ì • ê°€ê²Œ ì´ë¦„ì„ ì…ë ¥ë°›ì•„,
    ê°™ì€ ìƒê¶Œ/ì—…ì¢… ë‚´ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ì™€ ì£¼ìš” ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if df is None or store_name is None:
        return "ë°ì´í„° ë¡œë”© ì‹¤íŒ¨", None, None

    # 1. ì…ë ¥ë°›ì€ ê°€ê²Œì˜ 'ìƒê¶Œ'ê³¼ 'ì—…ì¢…' ì •ë³´ ì¡°íšŒ
    target_store_info = df[df['MCT_NM'] == store_name]
    if target_store_info.empty:
        return f"ë¶„ì„ ëŒ€ìƒì¸ '{store_name}' ì •ë³´ë¥¼ ë°ì´í„°ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None, None

    target_bzn = target_store_info['HPSN_MCT_BZN_CD_NM'].iloc[0]
    target_zcd = target_store_info['HPSN_MCT_ZCD_NM'].iloc[0]

    if pd.isna(target_bzn) or pd.isna(target_zcd):
        return f"'{store_name}'ì˜ ìƒê¶Œ ë˜ëŠ” ì—…ì¢… ì •ë³´ê°€ ëª…í™•í•˜ì§€ ì•Šì•„ ë¹„êµ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None, None

    # 2. ê°™ì€ ìƒê¶Œ & ê°™ì€ ì—…ì¢… ê°€ê²Œ ì¶”ì¶œ
    competitor_df = df[
        (df['HPSN_MCT_BZN_CD_NM'] == target_bzn) &
        (df['HPSN_MCT_ZCD_NM'] == target_zcd)
    ].copy()

    # 3. 'ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„' ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìˆœìœ„ ë¶€ì—¬
    df_final_list = competitor_df.sort_values(by='M12_SME_RY_SAA_PCE_RT', ascending=True).copy()
    df_final_list['Rank'] = range(1, len(df_final_list) + 1)

    # 4. ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
    my_store_rank_info = df_final_list[df_final_list['MCT_NM'] == store_name]
    first_place_store_info = df_final_list.iloc[0]

    return df_final_list, my_store_rank_info, first_place_store_info

# --- LLM í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ ---
def create_llm_prompt(my_rank, first_place):
    """'ë‚´ ê°€ê²Œ'ì™€ '1ìœ„ ê°€ê²Œ' ì •ë³´ë¥¼ ë°›ì•„ LLM í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""

    # (ê³ ê° í”„ë¡œí•„ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ë¹„êµ)
    customer_cols = [col for col in my_rank.index if 'RAT' in col and ('MAL' in col or 'FME' in col)]
    my_profile = my_rank[customer_cols]
    first_profile = first_place[customer_cols]

    # ë‘ í”„ë¡œí•„ ê°„ì˜ ì°¨ì´(ê²©ì°¨) ê³„ì‚°
    gap = first_profile - my_profile

    # ê°€ì¥ í° ê²©ì°¨(Gap)ë¥¼ ë³´ì´ëŠ” ê³ ê°ì¸µ ì°¾ê¸°
    biggest_gap_col = gap.idxmax()
    biggest_gap_value = gap.max()

    # ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€í™˜ (ì˜ˆì‹œ)
    col_to_korean = { 'M12_FME_30_RAT': '30ëŒ€ ì—¬ì„± ê³ ê° ë¹„ì¤‘' } # (ì‹¤ì œë¡œëŠ” ì „ì²´ ë”•ì…”ë„ˆë¦¬ í•„ìš”)
    gap_label = col_to_korean.get(biggest_gap_col, biggest_gap_col)

    prompt = f"""
ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… AI 'ë¹„ë°€ìƒë‹´ì‚¬'ì…ë‹ˆë‹¤.
'í‚´ìŠ¤**'ê°€ 1ìœ„ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ì „ëµì„ ì œì•ˆí•´ì•¼ í•©ë‹ˆë‹¤.

[ë°ì´í„° ë¶„ì„ ê·¼ê±°]
- ê°€ë§¹ì ëª…: {my_rank['MCT_NM']}
- í˜„ì¬ ìƒê¶Œ ë‚´ ìˆœìœ„: {my_rank['Rank']}ìœ„ (ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„: {my_rank['M12_SME_RY_SAA_PCE_RT']:.1f}%)

[1ìœ„ ë§¤ì¥ '{first_place['MCT_NM']}' ë¹„êµ ë¶„ì„]
- 1ìœ„ ë§¤ì¥ ìˆœìœ„: 1ìœ„ (ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„: {first_place['M12_SME_RY_SAA_PCE_RT']:.1f}%)
- **[í•µì‹¬ ê²©ì°¨]**: 1ìœ„ ë§¤ì¥ì€ '{gap_label}'ì´ {first_place[biggest_gap_col]:.1f}%ì¸ë° ë°˜í•´,
  'í‚´ìŠ¤**'ëŠ” {my_rank[biggest_gap_col]:.1f}%ë¡œ, {biggest_gap_value:.1f}%pì˜ í° ê²©ì°¨ë¥¼ ë³´ì…ë‹ˆë‹¤.

[ìš”ì²­ ì‚¬í•­]
1. ìœ„ [í•µì‹¬ ê²©ì°¨]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, 'í‚´ìŠ¤**'ê°€ 1ìœ„ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´
2. '{gap_label}'ì„ ì§‘ì¤‘ ê³µëµí•  ìˆ˜ ìˆëŠ” ë§ˆì¼€íŒ… í¬ì¸íŠ¸ 2ê°€ì§€ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
3. (ìš°ë¦¬ ì»¨ì…‰) **'ì„ ì„ í•œ ê°€ì„ ì €ë…'** ì‹œì¦Œì„±ì„ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ì œì•ˆí•´ì£¼ì„¸ìš”.
"""
    return prompt

# --- Streamlit UI êµ¬ì„± ---
st.title("ğŸ“ˆ 'í‚´ìŠ¤**' ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„")

# 1. ë°ì´í„° ë¡œë“œ
df_merged = load_data()

if df_merged is not None:
    # 2. 'í‚´ìŠ¤**'ì— ëŒ€í•œ ë¶„ì„ ë°”ë¡œ ì‹¤í–‰
    error_msg, rank_df, my_rank, first_place = None, None, None, None
    with st.spinner("'í‚´ìŠ¤**'ì˜ ê²½ìŸ í™˜ê²½ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        error_msg, rank_df, my_rank, first_place = analyze_competitors(df_merged, "í‚´ìŠ¤**")

    if error_msg:
        st.error(error_msg)
    else:
        st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        my_bzn = my_rank['HPSN_MCT_BZN_CD_NM'].iloc[0]
        my_zcd = my_rank['HPSN_MCT_ZCD_NM'].iloc[0]

        st.subheader(f"ğŸ“ '{my_bzn}' ìƒê¶Œ ë‚´ '{my_zcd}' ì—…ì¢… ìˆœìœ„")

        # 3. ë¶„ì„ ê²°ê³¼ í‘œ ì¶œë ¥
        columns_to_show = ['Rank', 'MCT_NM', 'M12_SME_RY_SAA_PCE_RT']
        st.dataframe(rank_df[columns_to_show].rename(columns={
            'Rank': 'ìˆœìœ„', 'MCT_NM': 'ê°€ê²Œ ì´ë¦„', 'M12_SME_RY_SAA_PCE_RT': 'ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„(%)'
        }))

        # 4. LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ë° (ê°€ìƒ) ë‹µë³€ ì¶œë ¥
        st.subheader("ğŸ’¡ 1ìœ„ ë‹¬ì„±ì„ ìœ„í•œ ë§ˆì¼€íŒ… ì „ëµ")

        prompt_for_llm = create_llm_prompt(my_rank.squeeze(), first_place.squeeze())

        # (ì‹¤ì œ ì±—ë´‡ì—ì„œëŠ” ì´ í”„ë¡¬í”„íŠ¸ë¥¼ Gemini APIë¡œ ì „ì†¡)
        st.code(prompt_for_llm, language='markdown') # (ë””ë²„ê¹…ìš©: ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ í™•ì¸)

        # (LLM ë‹µë³€ ì˜ˆì‹œ ì¶œë ¥)
        st.markdown("""
        ---
        #### **AI ì œì•ˆ:** 1ìœ„ ë‹¬ì„±ì„ ìœ„í•´ **'30ëŒ€ ì—¬ì„±'** ê³ ê°ì„ ê³µëµí•˜ì„¸ìš”!

        **[ì œì•ˆ 1] 'ê°€ì„ë°¤ ì¹˜ë§¥' ê°ì„± ë§ˆì¼€íŒ… (ì˜¨ë¼ì¸)**
        * 30ëŒ€ ì—¬ì„±ì´ í™œë°œí•œ **'ì¸ìŠ¤íƒ€ê·¸ë¨'**ì„ ê³µëµí•©ë‹ˆë‹¤. 'ê°€ì„ë°¤', 'ì„±ìˆ˜ë™', 'í…Œë¼ìŠ¤' í‚¤ì›Œë“œë¥¼ í™œìš©í•œ ê°ì„±ì ì¸ ë§¤ì¥ ì‚¬ì§„ì„ í¬ìŠ¤íŒ…í•˜ì„¸ìš”.
        * **[í™ë³´ ë¬¸êµ¬ ì˜ˆì‹œ]** "ì„ ì„ í•œ ê°€ì„ë°¤, ì„±ìˆ˜ë™ í…Œë¼ìŠ¤ì—ì„œ ì¹˜ë§¥ ì–´ë•Œìš”? ğŸ‚ ì§€ê¸ˆ í‚´ìŠ¤**ì—ì„œ 'ë¡œì œ ì¹˜í‚¨' ì‹ ë©”ë‰´ ì£¼ë¬¸ ì‹œ, í•˜ì´ë³¼ 1ì” ë¬´ë£Œ! #ì„±ìˆ˜ë™ë§›ì§‘ #ì„±ìˆ˜ì¹˜í‚¨ #ê°€ì„ë°¤ #ì¹˜ë§¥"

        **[ì œì•ˆ 2] '30ëŒ€ ì—¬ì„±' íƒ€ê²Ÿ ë©”ë‰´ ê°œë°œ (ì˜¤í”„ë¼ì¸)**
        * ê¸°ì¡´ ë©”ë‰´ ì™¸ì— 30ëŒ€ ì—¬ì„±ì´ ì„ í˜¸í•˜ëŠ” 'ë¡œì œ', 'ë°”ì§ˆ', 'ì½˜ì¹˜ì¦ˆ' ë“±ì„ í™œìš©í•œ ì‹ ë©”ë‰´ë¥¼ ê°œë°œí•˜ì—¬ '1ìœ„ ë§¤ì¥'ì˜ ê³ ê°ì„ ëŒì–´ì™€ì•¼ í•©ë‹ˆë‹¤.
        * **[ì‹¤í–‰ ë°©ì•ˆ]** 'ë¡œì œ ë–¡ë³¶ì´ ì¹˜í‚¨ ì„¸íŠ¸' ë˜ëŠ” 'ë°”ì§ˆ ì¹˜í‚¨ + í•˜ì´ë³¼ 2ì”' ì„¸íŠ¸ ë©”ë‰´ë¥¼ êµ¬ì„±í•˜ì—¬ ê°ë‹¨ê°€ì™€ ë§Œì¡±ë„ë¥¼ ë™ì‹œì— ë†’ì´ëŠ” ì „ëµì„ ì¶”ì²œí•©ë‹ˆë‹¤.
        """)